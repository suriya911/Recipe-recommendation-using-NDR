{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-01T22:59:50.556082Z",
     "iopub.status.busy": "2024-12-01T22:59:50.555206Z",
     "iopub.status.idle": "2024-12-01T22:59:51.793157Z",
     "shell.execute_reply": "2024-12-01T22:59:51.792117Z",
     "shell.execute_reply.started": "2024-12-01T22:59:50.556045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T22:59:51.795609Z",
     "iopub.status.busy": "2024-12-01T22:59:51.795023Z",
     "iopub.status.idle": "2024-12-01T23:00:02.015834Z",
     "shell.execute_reply": "2024-12-01T23:00:02.014740Z",
     "shell.execute_reply.started": "2024-12-01T22:59:51.795535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#mean Pooling to take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# loading model from HuggingFace Hub\n",
    "bi_enc_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "bi_enc_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# tokenizing sentences\n",
    "encoded_input = bi_enc_tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# computing the token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = bi_enc_model(**encoded_input)\n",
    "\n",
    "# pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# normalizing embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "# print(\"Sentence embeddings:\"\n",
    "# print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T23:00:02.018020Z",
     "iopub.status.busy": "2024-12-01T23:00:02.017390Z",
     "iopub.status.idle": "2024-12-01T23:00:06.200451Z",
     "shell.execute_reply": "2024-12-01T23:00:06.198403Z",
     "shell.execute_reply.started": "2024-12-01T23:00:02.017972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "cr_enc_model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "cr_enc_tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "features = cr_enc_tokenizer(['How many people live in Berlin?', 'How many people live in Berlin?'], ['Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.', 'New York City is famous for the Metropolitan Museum of Art.'],  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "cr_enc_model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = cr_enc_model(**features).logits\n",
    "    print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T23:00:06.204764Z",
     "iopub.status.busy": "2024-12-01T23:00:06.204268Z",
     "iopub.status.idle": "2024-12-01T23:00:14.433773Z",
     "shell.execute_reply": "2024-12-01T23:00:14.432753Z",
     "shell.execute_reply.started": "2024-12-01T23:00:06.204714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_recipe_df = pd.read_csv(\"/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T23:00:14.435683Z",
     "iopub.status.busy": "2024-12-01T23:00:14.435333Z",
     "iopub.status.idle": "2024-12-01T23:00:15.635284Z",
     "shell.execute_reply": "2024-12-01T23:00:15.634431Z",
     "shell.execute_reply.started": "2024-12-01T23:00:14.435646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "mongo_un = user_secrets.get_secret(\"mongo_un\")\n",
    "mongo_pw = user_secrets.get_secret(\"mongo_pw\")\n",
    "\n",
    "\n",
    "uri = f\"mongodb+srv://{mongo_un}:{mongo_pw}@cluster0.vcbeq3r.mongodb.net/?retryWrites=true&w=majority&appName=cluster0\"\n",
    "mongo_client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "\n",
    "# MongoDB connection setup\n",
    "# client = MongoClient(\"mongodb://localhost:27017/\")  # MongoDB URI\n",
    "db = mongo_client[\"NDR\"]  # database\n",
    "collection = db[\"test1\"]  # collection\n",
    "\n",
    "\n",
    "def get_processed_recipe(db_name, collection_name):\n",
    "    db = mongo_client[db_name]\n",
    "    collection = db[collection_name]  \n",
    "    data = collection.find()  # fetching all documents in the collection\n",
    "    \n",
    "    # converting the MongoDB cursor to a list of dictionaries\n",
    "    data_list = list(data)\n",
    "    \n",
    "    # also, if needed, converting to a pandas DataFrame\n",
    "    if len(data_list) > 0:\n",
    "        df = pd.DataFrame(data_list)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_bi_enc_embedding(sentence):\n",
    "    # print(type(sentence))\n",
    "    # print(sentence)\n",
    "    \n",
    "    encoded_input = bi_enc_tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # computing token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = bi_enc_model(**encoded_input)\n",
    "    \n",
    "    # pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    \n",
    "    return sentence_embeddings.squeeze()\n",
    "\n",
    "\n",
    "def get_cr_enc_score(s1, s2):\n",
    "    features = cr_enc_tokenizer([[s1, s2]],  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    cr_enc_model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = cr_enc_model(**features).logits\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T23:37:35.318873Z",
     "iopub.status.busy": "2024-12-01T23:37:35.318200Z",
     "iopub.status.idle": "2024-12-01T23:37:36.215526Z",
     "shell.execute_reply": "2024-12-01T23:37:36.214349Z",
     "shell.execute_reply.started": "2024-12-01T23:37:35.318825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_list = []\n",
    "\n",
    "query_df = get_processed_recipe('NDR','test3')\n",
    "\n",
    "\n",
    "for index, row in query_df.iterrows():\n",
    "\n",
    "    query_item = {}\n",
    "\n",
    "    query_item['recipe_id'] = row['recipe_id']\n",
    "\n",
    "    llm_output = row['llm_output']\n",
    "\n",
    "    text_between_quotes = []\n",
    "\n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'(?<=\\d\\.\\s)\"([^\"]+)\"'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "    \n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'\\*\\*Query\\s\\d+:\\*\\*\\s*\"([^\"]+)\"'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'Query\\s\\d+:\\s*\"([^\"]+)\"'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'\\*\\*Query:\\*\\*\\s*\"([^\"]+)\"'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'Query\\s\\d+:\\s*(.*?)(?=\\n\\n|Query\\s|$)'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'\\*\\*Query\\s\\d+\\*\\*\\s*\"([^\"]+)\"'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "    if len(text_between_quotes) == 0:\n",
    "        pattern = r'\\*\\*Query\\s\\d+:\\s*\\*\\*\\s*\"([^\"]+)\"'\n",
    "        text_between_quotes = re.findall(pattern, llm_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # text_between_quotes = re.findall(r'\\*\\*Query:\\*\\* \"(.*?)\"', llm_output)\n",
    "\n",
    "    # if len(text_between_quotes) != 5:\n",
    "    #     text_between_quotes = re.findall(r'\\d+\\.\\s*\"(.*?)\"', llm_output)\n",
    "        \n",
    "    query_item['query_list'] = text_between_quotes\n",
    "\n",
    "    output_list.append(query_item)\n",
    "\n",
    "    # output_list.append(text_between_quotes)\n",
    "\n",
    "# expanded_df = pd.DataFrame(output_list).explode(\"query_list\").reset_index(drop=True)\n",
    "# expanded_df = expanded_df[~expanded_df['query_list'].isna()]\n",
    "# raw_recipe_df_temp = raw_recipe_df[raw_recipe_df.id.astype(str).isin(list(expanded_df['recipe_id']))]\n",
    "# expanded_df = expanded_df.reset_index(drop = True).reset_index().rename(columns = {'index':'query_index'})\n",
    "# raw_recipe_df_temp = raw_recipe_df_temp.reset_index(drop = True).reset_index().rename(columns = {'index':'recipe_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T23:38:01.067791Z",
     "iopub.status.busy": "2024-12-01T23:38:01.067385Z",
     "iopub.status.idle": "2024-12-01T23:38:01.074535Z",
     "shell.execute_reply": "2024-12-01T23:38:01.073555Z",
     "shell.execute_reply.started": "2024-12-01T23:38:01.067747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_list[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T23:37:51.604947Z",
     "iopub.status.busy": "2024-12-01T23:37:51.603892Z",
     "iopub.status.idle": "2024-12-01T23:37:51.610475Z",
     "shell.execute_reply": "2024-12-01T23:37:51.609543Z",
     "shell.execute_reply.started": "2024-12-01T23:37:51.604892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(query_df.iloc[10]['llm_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:43:51.797091Z",
     "iopub.status.busy": "2024-12-01T10:43:51.796056Z",
     "iopub.status.idle": "2024-12-01T10:43:51.801326Z",
     "shell.execute_reply": "2024-12-01T10:43:51.800197Z",
     "shell.execute_reply.started": "2024-12-01T10:43:51.797047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:43:52.317773Z",
     "iopub.status.busy": "2024-12-01T10:43:52.317379Z",
     "iopub.status.idle": "2024-12-01T10:45:11.124557Z",
     "shell.execute_reply": "2024-12-01T10:45:11.123334Z",
     "shell.execute_reply.started": "2024-12-01T10:43:52.317739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bi_enc_model\n",
    "\n",
    "# bi_enc_tokenizer\n",
    "\n",
    "raw_recipe_df_temp['sentence'] = raw_recipe_df_temp.apply(lambda x: str(dict(x)),axis =1)\n",
    "raw_recipe_df_temp['sentence_embedding'] =  raw_recipe_df_temp['sentence'].apply(lambda x: get_bi_enc_embedding(x) )\n",
    "expanded_df['query_embedding'] =  expanded_df['query_list'].apply(lambda x: get_bi_enc_embedding(x) )\n",
    "query_embeddings = torch.stack(list(expanded_df['query_embedding'].values))\n",
    "sentence_embeddings = torch.stack(list(raw_recipe_df_temp['sentence_embedding'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:45:26.387649Z",
     "iopub.status.busy": "2024-12-01T10:45:26.387191Z",
     "iopub.status.idle": "2024-12-01T10:45:26.405223Z",
     "shell.execute_reply": "2024-12-01T10:45:26.404011Z",
     "shell.execute_reply.started": "2024-12-01T10:45:26.387610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(query_embeddings.shape)\n",
    "print(sentence_embeddings.shape)\n",
    "\n",
    "query_norm = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)  # [2210, 384]\n",
    "sentence_norm = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)  # [498, 384]\n",
    "\n",
    "# pairwise cosine similarity using matrix multiplication\n",
    "\n",
    "# print(cosine_similarities.shape)  # Output: torch.Size([2210, 498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:50:16.301860Z",
     "iopub.status.busy": "2024-12-01T10:50:16.301035Z",
     "iopub.status.idle": "2024-12-01T10:50:39.095394Z",
     "shell.execute_reply": "2024-12-01T10:50:39.093844Z",
     "shell.execute_reply.started": "2024-12-01T10:50:16.301814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cosine_similarities = torch.mm(query_norm, sentence_norm.T)  \n",
    "cross_query_sentence = pd.merge(raw_recipe_df_temp, expanded_df, how='cross')\n",
    "cross_query_sentence['similarity'] = cross_query_sentence.apply(lambda x: cosine_similarities[x['query_index'],x['recipe_index']] , axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:01:18.189940Z",
     "iopub.status.busy": "2024-12-01T11:01:18.188390Z",
     "iopub.status.idle": "2024-12-01T11:01:18.586881Z",
     "shell.execute_reply": "2024-12-01T11:01:18.585709Z",
     "shell.execute_reply.started": "2024-12-01T11:01:18.189867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cross_query_sentence['recipe_match'] = (cross_query_sentence['recipe_id'] == cross_query_sentence['id'].astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:01:19.787636Z",
     "iopub.status.busy": "2024-12-01T11:01:19.787205Z",
     "iopub.status.idle": "2024-12-01T11:01:19.821909Z",
     "shell.execute_reply": "2024-12-01T11:01:19.820366Z",
     "shell.execute_reply.started": "2024-12-01T11:01:19.787600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cross_query_sentence_sub = cross_query_sentence[cross_query_sentence['query_index'] < 100].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:11:34.311769Z",
     "iopub.status.busy": "2024-12-01T11:11:34.311316Z",
     "iopub.status.idle": "2024-12-01T11:11:38.851164Z",
     "shell.execute_reply": "2024-12-01T11:11:38.849798Z",
     "shell.execute_reply.started": "2024-12-01T11:11:34.311732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top_10 = cross_query_sentence_sub.sort_values(by=[\"query_index\", \"similarity\"], ascending=[True, False]).groupby('query_index').head(10)\n",
    "top_1 = cross_query_sentence_sub.sort_values(by=[\"query_index\", \"similarity\"], ascending=[True, False]).groupby('query_index').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:01:50.068728Z",
     "iopub.status.busy": "2024-12-01T11:01:50.068156Z",
     "iopub.status.idle": "2024-12-01T11:01:50.098129Z",
     "shell.execute_reply": "2024-12-01T11:01:50.096974Z",
     "shell.execute_reply.started": "2024-12-01T11:01:50.068673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out_summary = out.groupby('query_index').apply(lambda x: x['recipe_match'].sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:12:35.150502Z",
     "iopub.status.busy": "2024-12-01T11:12:35.150079Z",
     "iopub.status.idle": "2024-12-01T11:12:35.155603Z",
     "shell.execute_reply": "2024-12-01T11:12:35.154210Z",
     "shell.execute_reply.started": "2024-12-01T11:12:35.150467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cross_query_sentence[(cross_query_sentence['query_index'].isin(list(out_summary[out_summary[0] == 0]['query_index']))) & (cross_query_sentence['recipe_match'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:14:47.256248Z",
     "iopub.status.busy": "2024-12-01T11:14:47.255830Z",
     "iopub.status.idle": "2024-12-01T11:14:50.062136Z",
     "shell.execute_reply": "2024-12-01T11:14:50.060863Z",
     "shell.execute_reply.started": "2024-12-01T11:14:47.256211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top_1[(top_1['query_index'].isin(list(out_summary[out_summary[0] == 0]['query_index']))) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:14:25.675343Z",
     "iopub.status.busy": "2024-12-01T11:14:25.674924Z",
     "iopub.status.idle": "2024-12-01T11:14:26.658340Z",
     "shell.execute_reply": "2024-12-01T11:14:26.657204Z",
     "shell.execute_reply.started": "2024-12-01T11:14:25.675305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cross_query_sentence.to_csv(\"cross_query_sentence.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cross_query_sentence['recipe_match'] = (cross_query_sentence['id'].astype(str) == cross_query_sentence['recipe_id']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cross_query_sentence_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# cross_query_sentence_sub['cross_similarity'] = cross_query_sentence_sub.apply(lambda x: get_cr_enc_score(x['sentence'],x['query_list']) , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# cross_query_sentence_sub['cross_similarity_v1'] =  cross_query_sentence_sub['cross_similarity'].apply(lambda x: x[0][0])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 311962,
     "sourceId": 783630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
